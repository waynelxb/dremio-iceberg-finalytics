{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc71f1ce-97ce-4e88-a374-747acfc540fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import nbimporter\n",
    "from datetime import datetime, date\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType,  DateType, TimestampType\n",
    "from pyspark.sql.functions import to_date, to_timestamp\n",
    "from lab_table_manager import TableManager\n",
    "import yfinance as yf\n",
    "from lab_finalytics_database import FinalyticsDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e29c97-3bf7-4c3f-8608-65c8a39b910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12 added as a dependency\n",
      "software.amazon.awssdk#bundle added as a dependency\n",
      "software.amazon.awssdk#url-connection-client added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ea40d514-a1b2-43e0-8cf5-fdefc5e77dca;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.7.3 in central\n",
      "\tfound org.checkerframework#checker-qual;3.42.0 in central\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 in central\n",
      "\tfound org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.77.1 in central\n",
      "\tfound software.amazon.awssdk#bundle;2.24.8 in central\n",
      "\tfound software.amazon.awssdk#url-connection-client;2.24.8 in central\n",
      "\tfound software.amazon.awssdk#utils;2.24.8 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in central\n",
      "\tfound software.amazon.awssdk#annotations;2.24.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound software.amazon.awssdk#http-client-spi;2.24.8 in central\n",
      "\tfound software.amazon.awssdk#metrics-spi;2.24.8 in central\n",
      ":: resolution report :: resolve 401ms :: artifacts dl 36ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.42.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.7.3 from central in [default]\n",
      "\torg.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.77.1 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\tsoftware.amazon.awssdk#annotations;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#http-client-spi;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#metrics-spi;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#url-connection-client;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#utils;2.24.8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   0   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ea40d514-a1b2-43e0-8cf5-fdefc5e77dca\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/9ms)\n",
      "24/12/25 01:34:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"cfg_connections.yaml\",\"r\") as file:\n",
    "    config=yaml.safe_load(file)\n",
    "    catalog_uri = config['docker_env']['catalog_uri'] \n",
    "    warehouse = config['docker_env']['warehouse']     # Minio Address to Write to\n",
    "    storage_uri = config['docker_env']['storage_uri'] # Minio IP address from docker inspec\n",
    "\n",
    "# Configure Spark with necessary packages and Iceberg/Nessie settings\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('finalytics_app')\n",
    "        # Include necessary packages\n",
    "        .set('spark.jars.packages',\n",
    "             'org.postgresql:postgresql:42.7.3,'\n",
    "             'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,'\n",
    "             'org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1,'\n",
    "             'software.amazon.awssdk:bundle:2.24.8,'\n",
    "             'software.amazon.awssdk:url-connection-client:2.24.8')\n",
    "        # Enable Iceberg and Nessie extensions\n",
    "        .set('spark.sql.extensions', \n",
    "             'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,'\n",
    "             'org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        # Configure Nessie catalog\n",
    "        .set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.nessie.uri', catalog_uri)\n",
    "        .set('spark.sql.catalog.nessie.ref', 'main')\n",
    "        .set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    "        .set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "        # Set Minio as the S3 endpoint for Iceberg storage\n",
    "        .set('spark.sql.catalog.nessie.s3.endpoint', storage_uri)\n",
    "        .set('spark.sql.catalog.nessie.warehouse', warehouse)\n",
    "        .set('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')       \n",
    ")   \n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()  \n",
    "# Create the \"sales\" namespace\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS nessie.raw;\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f1668e-6c02-40a4-8d8b-4c1e522420fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_yfinance_record(symbol_date_pairs):\n",
    "    try:\n",
    "        symbol, start_date = symbol_date_pairs\n",
    "        # Fetch stock data using yfinance\n",
    "        quote = yf.Ticker(symbol)\n",
    "        current_date = date.today()\n",
    "        hist = quote.history(start=start_date, end=current_date)\n",
    "\n",
    "        # Reset index to include Date as a column and format it\n",
    "        hist.reset_index(inplace=True)\n",
    "        # hist['Date'] = hist['Date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        # hist['Date'] = hist['Date'].dt.strftime('%Y-%m-%d').date()\n",
    "        hist[\"Date\"] = hist[\"Date\"].dt.date \n",
    "        \n",
    "        # Add symbol and import_time to each row\n",
    "        record_list = [\n",
    "            tuple(row) + (symbol, import_time) for row in hist.itertuples(index=False)\n",
    "        ]\n",
    "        \n",
    "        # print(record_list)\n",
    "        return record_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "        return []  # Return an empty list on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7a8628-9f57-478a-9ca5-5e500fceb7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parallel_fetch_yfinance_record(symbol_date_pairs, record_schema):    \n",
    "    # Distribute (symbol, start_date) pairs across Spark workers\n",
    "    record_rdd = spark.sparkContext.parallelize(symbol_date_pairs)\n",
    "    \n",
    "    # Fetch data in parallel\n",
    "    mapped_record_rdd = record_rdd.flatMap(fetch_yfinance_record)\n",
    "\n",
    "    # Convert RDD to DataFrame\n",
    "    result_df = spark.createDataFrame(mapped_record_rdd, schema=record_schema)\n",
    "\n",
    "    # Show or save the results\n",
    "    # result_df.show()\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b02da3-a584-4dbd-b44b-ccd3d5bbed1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_raw_eod_yfinance(symbol_date_pairs, sink_table, schema_config_file):\n",
    "    table_manager=TableManager(schema_config_file)\n",
    "    regd_struct_type=table_manager.get_struct_type(sink_table)   \n",
    "    \n",
    "    # regd_column_list = table_manager.get_column_list(sink_table)\n",
    "    create_table_script = table_manager.get_create_table_query(sink_table)\n",
    "    spark.sql(create_table_script)\n",
    "    \n",
    "    df_raw_eod_yfinance=parallel_fetch_yfinance_record(symbol_date_pairs, regd_struct_type)\n",
    "    # df_raw_eod_yfinance = df_raw_eod_yfinance.withColumn(\"date\", to_date(\"date\", \"yyyy-MM-dd\")).withColumn(\"import_time\", to_timestamp(\"import_time\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "  \n",
    "    # df_raw_eod_yfinance.writeTo(sink_table).append()\n",
    "    df_raw_eod_yfinance.write.mode(\"overwrite\").saveAsTable(sink_table)    \n",
    "    # df_raw_eod_yfinance.writeTo(sink_table).overwritePartitions()\n",
    "    \n",
    "    print(f\"{sink_table} has been loaded\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87e4e507-3cca-4314-a3c6-c5c6206fe818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nessie.raw.stock_eod_yfinance has been loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "  \n",
    "# symbol_start_date_pairs = [\n",
    "#     ('AAPL', '2024-12-10'),\n",
    "#     ('MSFT', '2024-12-10'),\n",
    "#     ('GOOGL', '2024-12-10'),\n",
    "# ]\n",
    "\n",
    "conn_config_file='cfg_connections.yaml'\n",
    "finalytics=FinalyticsDB(conn_config_file)\n",
    "\n",
    "query=\"select symbol, start_date from fin.vw_etl_stock_eod_start_date limit 30\"\n",
    "symbol_start_date_pairs=finalytics.get_symbol_start_date_pairs(query)\n",
    "finalytics_url=finalytics.jdbc_url\n",
    "finalytics_driver=finalytics.driver\n",
    "\n",
    "regd_schema_config_file='cfg_registered_table_schemas.yaml'\n",
    "sink_table='nessie.raw.stock_eod_yfinance'\n",
    "\n",
    "import_time = datetime.now().isoformat()\n",
    "load_raw_eod_yfinance(symbol_start_date_pairs, sink_table, regd_schema_config_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3904a34-d834-4d28-87b6-21f2b271fbb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     232|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*) from nessie.raw.stock_eod_yfinance').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ff6a1d9-c5fa-4697-9b7b-b257048855eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=spark.read.table(sink_table)          \n",
    "pg_table = \"stage.stock_eod_quote_yahoo_new\"  # Replace with the PostgreSQL table name\n",
    "# # Write Delta table DataFrame to PostgreSQL\n",
    "df.write.jdbc(url=finalytics_url, table=pg_table, mode=\"overwrite\", properties={\"driver\": finalytics_driver})\n",
    "\n",
    "query = \"call fin.usp_load_stock_eod();\"\n",
    "finalytics.execute_sql_script(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06376922-1939-4c55-bde2-0be33707d47a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         import_time|\n",
      "+--------------------+\n",
      "|2024-12-25T01:44:...|\n",
      "|2024-12-25T01:44:...|\n",
      "|2024-12-25T01:44:...|\n",
      "|2024-12-25T01:44:...|\n",
      "|2024-12-25T01:44:...|\n",
      "|2024-12-25T01:44:...|\n",
      "|2024-12-25T01:44:...|\n",
      "|2024-12-25T01:44:...|\n",
      "|2024-12-25T01:44:...|\n",
      "|2024-12-25T01:44:...|\n",
      "|2024-12-25T01:44:...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select import_time from nessie.raw.stock_eod_yfinance order by import_time desc').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa57e00f-96ea-4db2-8a36-6d17d01d02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Fetch historical data for AAPL\n",
    "ticker = yf.Ticker(\"AAPL\")\n",
    "history = ticker.history(period=\"1mo\", interval=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cc75bb9-9d26-4eca-86be-d626dfe3669f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2024-11-25 00:00:00-05:00  231.460007  233.250000  229.740005  232.869995   \n",
      "2024-11-26 00:00:00-05:00  233.330002  235.570007  233.330002  235.059998   \n",
      "2024-11-27 00:00:00-05:00  234.470001  235.690002  233.809998  234.929993   \n",
      "2024-11-29 00:00:00-05:00  234.809998  237.809998  233.970001  237.330002   \n",
      "2024-12-02 00:00:00-05:00  237.270004  240.789993  237.160004  239.589996   \n",
      "2024-12-03 00:00:00-05:00  239.809998  242.759995  238.899994  242.649994   \n",
      "2024-12-04 00:00:00-05:00  242.869995  244.110001  241.250000  243.009995   \n",
      "2024-12-05 00:00:00-05:00  243.990005  244.539993  242.130005  243.039993   \n",
      "2024-12-06 00:00:00-05:00  242.910004  244.630005  242.080002  242.839996   \n",
      "2024-12-09 00:00:00-05:00  241.830002  247.240005  241.750000  246.750000   \n",
      "2024-12-10 00:00:00-05:00  246.889999  248.210007  245.339996  247.770004   \n",
      "2024-12-11 00:00:00-05:00  247.960007  250.800003  246.259995  246.490005   \n",
      "2024-12-12 00:00:00-05:00  246.889999  248.740005  245.679993  247.960007   \n",
      "2024-12-13 00:00:00-05:00  247.820007  249.289993  246.240005  248.130005   \n",
      "2024-12-16 00:00:00-05:00  247.990005  251.380005  247.649994  251.039993   \n",
      "2024-12-17 00:00:00-05:00  250.080002  253.830002  249.779999  253.479996   \n",
      "2024-12-18 00:00:00-05:00  252.160004  254.279999  247.740005  248.050003   \n",
      "2024-12-19 00:00:00-05:00  247.500000  252.000000  247.089996  249.789993   \n",
      "2024-12-20 00:00:00-05:00  248.039993  255.000000  245.690002  254.490005   \n",
      "2024-12-23 00:00:00-05:00  254.770004  255.649994  253.449997  255.270004   \n",
      "2024-12-24 00:00:00-05:00  255.369995  258.209991  255.309998  258.200012   \n",
      "\n",
      "                              Volume  Dividends  Stock Splits  \n",
      "Date                                                           \n",
      "2024-11-25 00:00:00-05:00   90152800        0.0           0.0  \n",
      "2024-11-26 00:00:00-05:00   45986200        0.0           0.0  \n",
      "2024-11-27 00:00:00-05:00   33498400        0.0           0.0  \n",
      "2024-11-29 00:00:00-05:00   28481400        0.0           0.0  \n",
      "2024-12-02 00:00:00-05:00   48137100        0.0           0.0  \n",
      "2024-12-03 00:00:00-05:00   38861000        0.0           0.0  \n",
      "2024-12-04 00:00:00-05:00   44383900        0.0           0.0  \n",
      "2024-12-05 00:00:00-05:00   40033900        0.0           0.0  \n",
      "2024-12-06 00:00:00-05:00   36870600        0.0           0.0  \n",
      "2024-12-09 00:00:00-05:00   44649200        0.0           0.0  \n",
      "2024-12-10 00:00:00-05:00   36914800        0.0           0.0  \n",
      "2024-12-11 00:00:00-05:00   45205800        0.0           0.0  \n",
      "2024-12-12 00:00:00-05:00   32777500        0.0           0.0  \n",
      "2024-12-13 00:00:00-05:00   33155300        0.0           0.0  \n",
      "2024-12-16 00:00:00-05:00   51694800        0.0           0.0  \n",
      "2024-12-17 00:00:00-05:00   51356400        0.0           0.0  \n",
      "2024-12-18 00:00:00-05:00   56774100        0.0           0.0  \n",
      "2024-12-19 00:00:00-05:00   60882300        0.0           0.0  \n",
      "2024-12-20 00:00:00-05:00  147495300        0.0           0.0  \n",
      "2024-12-23 00:00:00-05:00   40858800        0.0           0.0  \n",
      "2024-12-24 00:00:00-05:00   20965006        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6116ddb-ed93-4f5d-967c-b5fcdd91fa3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quote = yf.Ticker('C')\n",
    "start_date = '2024-12-01'\n",
    "current_date = date.today()\n",
    "# print(start_date+timedelta(days=1))\n",
    "\n",
    "hist = quote.history(start=start_date, end=current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "519a296c-96e0-41de-ae90-a9584ccbd979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Open       High        Low      Close  \\\n",
      "Date                                                                    \n",
      "2024-12-02 00:00:00-05:00  71.260002  71.650002  70.879997  71.389999   \n",
      "2024-12-03 00:00:00-05:00  72.190002  72.800003  71.269997  71.419998   \n",
      "2024-12-04 00:00:00-05:00  71.500000  71.720001  70.500000  71.500000   \n",
      "2024-12-05 00:00:00-05:00  71.830002  72.849998  71.639999  72.230003   \n",
      "2024-12-06 00:00:00-05:00  72.309998  72.599998  71.709999  72.150002   \n",
      "2024-12-09 00:00:00-05:00  72.300003  72.800003  71.839996  71.860001   \n",
      "2024-12-10 00:00:00-05:00  72.000000  73.379997  71.580002  72.500000   \n",
      "2024-12-11 00:00:00-05:00  73.000000  73.260002  71.269997  71.959999   \n",
      "2024-12-12 00:00:00-05:00  71.860001  72.330002  71.410004  71.430000   \n",
      "2024-12-13 00:00:00-05:00  71.709999  71.910004  70.760002  71.010002   \n",
      "2024-12-16 00:00:00-05:00  71.269997  71.769997  70.830002  71.489998   \n",
      "2024-12-17 00:00:00-05:00  70.900002  71.349998  70.800003  71.120003   \n",
      "2024-12-18 00:00:00-05:00  71.180000  71.470001  67.919998  68.120003   \n",
      "2024-12-19 00:00:00-05:00  69.209999  69.839996  68.320000  68.419998   \n",
      "2024-12-20 00:00:00-05:00  68.290001  70.260002  68.029999  69.190002   \n",
      "2024-12-23 00:00:00-05:00  69.360001  69.879997  68.870003  69.769997   \n",
      "2024-12-24 00:00:00-05:00  70.099998  71.209999  69.934998  71.000000   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2024-12-02 00:00:00-05:00  11932600        0.0           0.0  \n",
      "2024-12-03 00:00:00-05:00  17544200        0.0           0.0  \n",
      "2024-12-04 00:00:00-05:00  12331900        0.0           0.0  \n",
      "2024-12-05 00:00:00-05:00  14307600        0.0           0.0  \n",
      "2024-12-06 00:00:00-05:00   8781100        0.0           0.0  \n",
      "2024-12-09 00:00:00-05:00  11957500        0.0           0.0  \n",
      "2024-12-10 00:00:00-05:00  16833400        0.0           0.0  \n",
      "2024-12-11 00:00:00-05:00  22533600        0.0           0.0  \n",
      "2024-12-12 00:00:00-05:00   8893000        0.0           0.0  \n",
      "2024-12-13 00:00:00-05:00   9819900        0.0           0.0  \n",
      "2024-12-16 00:00:00-05:00  11833800        0.0           0.0  \n",
      "2024-12-17 00:00:00-05:00  12639000        0.0           0.0  \n",
      "2024-12-18 00:00:00-05:00  18028000        0.0           0.0  \n",
      "2024-12-19 00:00:00-05:00  13464300        0.0           0.0  \n",
      "2024-12-20 00:00:00-05:00  27720100        0.0           0.0  \n",
      "2024-12-23 00:00:00-05:00   8248000        0.0           0.0  \n",
      "2024-12-24 00:00:00-05:00   6110253        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca139d-8d89-4754-a48d-90010853b91d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
