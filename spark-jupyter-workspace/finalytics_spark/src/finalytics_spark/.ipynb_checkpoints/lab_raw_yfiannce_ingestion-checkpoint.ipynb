{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc71f1ce-97ce-4e88-a374-747acfc540fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import nbimporter\n",
    "from datetime import datetime, date\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "from raw_yfinance_ingestion import RawYFIngestion  \n",
    "from lab_registered_tables import TableManager\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8e29c97-3bf7-4c3f-8608-65c8a39b910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"config_connections.yaml\",\"r\") as file:\n",
    "    config=yaml.safe_load(file)\n",
    "    catalog_uri = config['docker_env']['catalog_uri'] \n",
    "    warehouse = config['docker_env']['warehouse']     # Minio Address to Write to\n",
    "    storage_uri = config['docker_env']['storage_uri'] # Minio IP address from docker inspec\n",
    "\n",
    "# Configure Spark with necessary packages and Iceberg/Nessie settings\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('finalytics_app')\n",
    "        # Include necessary packages\n",
    "        .set('spark.jars.packages',\n",
    "             'org.postgresql:postgresql:42.7.3,'\n",
    "             'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,'\n",
    "             'org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1,'\n",
    "             'software.amazon.awssdk:bundle:2.24.8,'\n",
    "             'software.amazon.awssdk:url-connection-client:2.24.8')\n",
    "        # Enable Iceberg and Nessie extensions\n",
    "        .set('spark.sql.extensions', \n",
    "             'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,'\n",
    "             'org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "        # Configure Nessie catalog\n",
    "        .set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "        .set('spark.sql.catalog.nessie.uri', catalog_uri)\n",
    "        .set('spark.sql.catalog.nessie.ref', 'main')\n",
    "        .set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    "        .set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "        # Set Minio as the S3 endpoint for Iceberg storage\n",
    "        .set('spark.sql.catalog.nessie.s3.endpoint', storage_uri)\n",
    "        .set('spark.sql.catalog.nessie.warehouse', warehouse)\n",
    "        .set('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')       \n",
    ")   \n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()  \n",
    "# Create the \"sales\" namespace\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS nessie.raw;\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43f1668e-6c02-40a4-8d8b-4c1e522420fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_yfinance_record(multi_param_pairs):\n",
    "    try:\n",
    "        symbol, start_date = multi_param_pairs\n",
    "        # Fetch stock data using yfinance\n",
    "        quote = yf.Ticker(symbol)\n",
    "        current_date = date.today()\n",
    "        hist = quote.history(start=start_date, end=current_date)\n",
    "\n",
    "        # Reset index to include Date as a column and format it\n",
    "        hist.reset_index(inplace=True)\n",
    "        hist['Date'] = hist['Date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Add symbol and import_time to each row\n",
    "        record_list = [\n",
    "            tuple(row) + (symbol, import_time) for row in hist.itertuples(index=False)\n",
    "        ]\n",
    "\n",
    "        return record_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "        return []  # Return an empty list on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afab4b13-8598-414f-8e80-14ec3828ed3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to process the records (pass through parameters)\n",
    "def process_yfinance_record(single_param_pair):\n",
    "    # print(f\"Processing {single_param_pair}\")\n",
    "    return fetch_yfinance_record(single_param_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc24f51b-ca74-4232-ae7c-eda5bafa83ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parallel fetch function\n",
    "def parallel_fetch(multi_param_pairs):\n",
    "    # Create RDD from the input parameter pairs\n",
    "    record_rdd = spark.sparkContext.parallelize(multi_param_pairs)\n",
    "\n",
    "    # Use flatMap to return a flattened list of records\n",
    "    results_rdd = record_rdd.flatMap(process_yfinance_record)\n",
    "\n",
    "    # Collect the results from the RDD and convert to a list of tuples\n",
    "    # results = results_rdd.collect()        \n",
    "    df = spark.createDataFrame(results_rdd, registered_column_list)   \n",
    "    \n",
    "    return df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78b02da3-a584-4dbd-b44b-ccd3d5bbed1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+------+------+---------+---------+------------+------+--------------------+\n",
      "|               date|  open|  high|   low| close|   volume|dividends|stock_splits|symbol|         import_time|\n",
      "+-------------------+------+------+------+------+---------+---------+------------+------+--------------------+\n",
      "|2024-12-10 00:00:00|246.89|248.21|245.34|247.77| 36914800|      0.0|         0.0|  AAPL|2024-12-24 04:04:...|\n",
      "|2024-12-11 00:00:00|247.96| 250.8|246.26|246.49| 45205800|      0.0|         0.0|  AAPL|2024-12-24 04:04:...|\n",
      "|2024-12-12 00:00:00|246.89|248.74|245.68|247.96| 32777500|      0.0|         0.0|  AAPL|2024-12-24 04:04:...|\n",
      "|2024-12-13 00:00:00|247.82|249.29|246.24|248.13| 33155300|      0.0|         0.0|  AAPL|2024-12-24 04:04:...|\n",
      "|2024-12-16 00:00:00|247.99|251.38|247.65|251.04| 51694800|      0.0|         0.0|  AAPL|2024-12-24 04:04:...|\n",
      "|2024-12-17 00:00:00|250.08|253.83|249.78|253.48| 51356400|      0.0|         0.0|  AAPL|2024-12-24 04:04:...|\n",
      "|2024-12-18 00:00:00|252.16|254.28|247.74|248.05| 56774100|      0.0|         0.0|  AAPL|2024-12-24 04:04:...|\n",
      "|2024-12-19 00:00:00| 247.5| 252.0|247.09|249.79| 60882300|      0.0|         0.0|  AAPL|2024-12-24 04:04:...|\n",
      "|2024-12-20 00:00:00|248.04| 255.0|245.69|254.49|147495300|      0.0|         0.0|  AAPL|2024-12-24 04:04:...|\n",
      "|2024-12-23 00:00:00|254.77|255.65|253.45|255.27| 40828600|      0.0|         0.0|  AAPL|2024-12-24 04:04:...|\n",
      "|2024-12-10 00:00:00|444.39|449.62| 441.6|443.33| 18469500|      0.0|         0.0|  MSFT|2024-12-24 04:04:...|\n",
      "|2024-12-11 00:00:00|444.05|450.35|444.05|448.99| 19200200|      0.0|         0.0|  MSFT|2024-12-24 04:04:...|\n",
      "|2024-12-12 00:00:00|449.11|456.16|449.11|449.56| 20834800|      0.0|         0.0|  MSFT|2024-12-24 04:04:...|\n",
      "|2024-12-13 00:00:00|448.44|451.43|445.58|447.27| 20177800|      0.0|         0.0|  MSFT|2024-12-24 04:04:...|\n",
      "|2024-12-16 00:00:00|447.27|452.18|445.28|451.59| 23598800|      0.0|         0.0|  MSFT|2024-12-24 04:04:...|\n",
      "|2024-12-17 00:00:00|451.01|455.29|449.57|454.46| 22733500|      0.0|         0.0|  MSFT|2024-12-24 04:04:...|\n",
      "|2024-12-18 00:00:00|451.32|452.65|437.02|437.39| 24444500|      0.0|         0.0|  MSFT|2024-12-24 04:04:...|\n",
      "|2024-12-19 00:00:00|441.62|443.18|436.32|437.03| 22963700|      0.0|         0.0|  MSFT|2024-12-24 04:04:...|\n",
      "|2024-12-20 00:00:00|433.11|443.74|428.63| 436.6| 64263700|      0.0|         0.0|  MSFT|2024-12-24 04:04:...|\n",
      "|2024-12-23 00:00:00|436.74|437.65|432.83|435.25| 19127000|      0.0|         0.0|  MSFT|2024-12-24 04:04:...|\n",
      "+-------------------+------+------+------+------+---------+---------+------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of stock symbols and start dates\n",
    "yf_param_pairs = [\n",
    "    ('AAPL', '2024-12-10'),\n",
    "    ('MSFT', '2024-12-10'),\n",
    "    ('GOOGL', '2024-12-10'),\n",
    "]\n",
    "\n",
    "import_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.\") + str(datetime.now().microsecond)[:3]\n",
    "zone='raw'\n",
    "sink_table='nessie.raw.stock_eod_yfinance'\n",
    "config_file_path='registered_table_schemas.yaml'\n",
    "table_manager=TableManager(config_file_path)\n",
    "registered_column_list = table_manager.get_column_list(sink_table)\n",
    "create_table_query = table_manager.get_create_table_query(table_name)\n",
    "\n",
    "# Fetch data in parallel\n",
    "df_raw_eod_yfinance = parallel_fetch(yf_param_pairs)\n",
    "# df_raw_eod_yfinance.show()\n",
    "\n",
    "# Print the query\n",
    "# print(create_table_query)\n",
    "spark.sql(create_table_query)\n",
    "\n",
    "\n",
    "df_raw_eod_yfinance.writeTo(sink_table).append()\n",
    "spark.sql(f\"select * from {sink_table}\").show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3100b031-7748-460b-963f-16c51f4b185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS nessie.raw.stock_eod_yfinance (date string, open float, high float, low float, close float, volume int, dividends float, stock_splits float, symbol string, import_time string)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Initialize the TableManager with the YAML file path\n",
    "\n",
    "config_file_path = \"registered_table_schemas.yaml\"\n",
    "table_manager = TableManager(config_file_path)\n",
    "\n",
    "# Get the CREATE TABLE query\n",
    "table_name = \"nessie.raw.stock_eod_yfinance\"\n",
    "create_table_query = table_manager.get_create_table_query(table_name)\n",
    "\n",
    "# Print the query\n",
    "print(create_table_query)\n",
    "\n",
    "spark.sql(create_table_query)\n",
    "spark.sql('select * from nessie.raw.stock_eod_yfinance')\n",
    "\n",
    "df_raw_eod_yfinance.writeTo(\"nessie.raw.stock_eod_yfinance\").append()\n",
    "\n",
    "\n",
    "\n",
    "# # Convert the data into a DataFrame\n",
    "# sales_df = spark.createDataFrame(sales_data, schema)\n",
    "\n",
    "# # Create the \"sales\" namespace\n",
    "# spark.sql(\"CREATE NAMESPACE IF NOT EXISTS nessie.sales;\").show()\n",
    "\n",
    "# # Write the DataFrame to an Iceberg table in the Nessie catalog\n",
    "# sales_df.writeTo(\"nessie.sales.sales_data_raw\").createOrReplace()\n",
    "\n",
    "# # Verify by reading from the Iceberg table\n",
    "# spark.read.table(\"nessie.sales.sales_data_raw\").show()\n",
    "\n",
    "# # Stop the Spark session\n",
    "# spark.stop()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ff6a1d9-c5fa-4697-9b7b-b257048855eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+------+------+---------+---------+------------+------+--------------------+\n",
      "|               date|  open|  high|   low| close|   volume|dividends|stock_splits|symbol|         import_time|\n",
      "+-------------------+------+------+------+------+---------+---------+------------+------+--------------------+\n",
      "|2024-12-10 00:00:00|246.89|248.21|245.34|247.77| 36914800|      0.0|         0.0|  AAPL|2024-12-24 03:53:...|\n",
      "|2024-12-11 00:00:00|247.96| 250.8|246.26|246.49| 45205800|      0.0|         0.0|  AAPL|2024-12-24 03:53:...|\n",
      "|2024-12-12 00:00:00|246.89|248.74|245.68|247.96| 32777500|      0.0|         0.0|  AAPL|2024-12-24 03:53:...|\n",
      "|2024-12-13 00:00:00|247.82|249.29|246.24|248.13| 33155300|      0.0|         0.0|  AAPL|2024-12-24 03:53:...|\n",
      "|2024-12-16 00:00:00|247.99|251.38|247.65|251.04| 51694800|      0.0|         0.0|  AAPL|2024-12-24 03:53:...|\n",
      "|2024-12-17 00:00:00|250.08|253.83|249.78|253.48| 51356400|      0.0|         0.0|  AAPL|2024-12-24 03:53:...|\n",
      "|2024-12-18 00:00:00|252.16|254.28|247.74|248.05| 56774100|      0.0|         0.0|  AAPL|2024-12-24 03:53:...|\n",
      "|2024-12-19 00:00:00| 247.5| 252.0|247.09|249.79| 60882300|      0.0|         0.0|  AAPL|2024-12-24 03:53:...|\n",
      "|2024-12-20 00:00:00|248.04| 255.0|245.69|254.49|147495300|      0.0|         0.0|  AAPL|2024-12-24 03:53:...|\n",
      "|2024-12-23 00:00:00|254.77|255.65|253.45|255.27| 40828600|      0.0|         0.0|  AAPL|2024-12-24 03:53:...|\n",
      "|2024-12-10 00:00:00|444.39|449.62| 441.6|443.33| 18469500|      0.0|         0.0|  MSFT|2024-12-24 03:53:...|\n",
      "|2024-12-11 00:00:00|444.05|450.35|444.05|448.99| 19200200|      0.0|         0.0|  MSFT|2024-12-24 03:53:...|\n",
      "|2024-12-12 00:00:00|449.11|456.16|449.11|449.56| 20834800|      0.0|         0.0|  MSFT|2024-12-24 03:53:...|\n",
      "|2024-12-13 00:00:00|448.44|451.43|445.58|447.27| 20177800|      0.0|         0.0|  MSFT|2024-12-24 03:53:...|\n",
      "|2024-12-16 00:00:00|447.27|452.18|445.28|451.59| 23598800|      0.0|         0.0|  MSFT|2024-12-24 03:53:...|\n",
      "|2024-12-17 00:00:00|451.01|455.29|449.57|454.46| 22733500|      0.0|         0.0|  MSFT|2024-12-24 03:53:...|\n",
      "|2024-12-18 00:00:00|451.32|452.65|437.02|437.39| 24444500|      0.0|         0.0|  MSFT|2024-12-24 03:53:...|\n",
      "|2024-12-19 00:00:00|441.62|443.18|436.32|437.03| 22963700|      0.0|         0.0|  MSFT|2024-12-24 03:53:...|\n",
      "|2024-12-20 00:00:00|433.11|443.74|428.63| 436.6| 64263700|      0.0|         0.0|  MSFT|2024-12-24 03:53:...|\n",
      "|2024-12-23 00:00:00|436.74|437.65|432.83|435.25| 19127000|      0.0|         0.0|  MSFT|2024-12-24 03:53:...|\n",
      "+-------------------+------+------+------+------+---------+---------+------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql('select * from nessie.raw.stock_eod_yfinance').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a8d50-9ff1-45c9-8155-092bef2b8a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae9695-827d-4273-989b-0fd2598d0976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851c8ad-f653-46ad-b2db-780db8a6c018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
