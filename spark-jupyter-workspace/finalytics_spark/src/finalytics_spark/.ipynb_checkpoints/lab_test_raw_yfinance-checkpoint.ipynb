{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f1668e-6c02-40a4-8d8b-4c1e522420fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import nbimporter\n",
    "from datetime import datetime, date\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType,  DateType, TimestampType\n",
    "from pyspark.sql.functions import to_date, to_timestamp\n",
    "from lab_table_manager import TableManager\n",
    "import yfinance as yf\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "def fetch_yfinance_record(symbol_date_pairs):\n",
    "    try:\n",
    "        symbol, start_date = symbol_date_pairs\n",
    "        # Fetch stock data using yfinance\n",
    "        quote = yf.Ticker(symbol)\n",
    "        current_date = date.today()\n",
    "        hist = quote.history(start=start_date, end=current_date)\n",
    "\n",
    "        # Reset index to include Date as a column and format it\n",
    "        hist.reset_index(inplace=True)\n",
    "        hist[\"Date\"] = hist[\"Date\"].dt.date\n",
    "        \n",
    "        # limit and stablize the fields of hist\n",
    "        hist = hist[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']]\n",
    "        import_time = datetime.now().isoformat()\n",
    "        # Add symbol and import_time to each row\n",
    "        record_list = [\n",
    "            tuple(row) + (symbol, import_time) for row in hist.itertuples(index=False)\n",
    "        ]\n",
    "        random_sleep_time = random.uniform(0.1, 0.9)\n",
    "        time.sleep(random_sleep_time)\n",
    "\n",
    "        # print(record_list)\n",
    "        return record_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "        return []  # Return an empty list on error\n",
    "\n",
    "\n",
    "# def xparallel_fetch_yfinance_record(spark, symbol_date_pairs, record_schema):\n",
    "\n",
    "def xparallel_fetch_yfinance_record(spark, symbol_date_pairs, record_schema):\n",
    "    try:\n",
    "        # Initialize Spark session\n",
    "\n",
    "        # connection_config_file=\"cfg_connections.yaml\"\n",
    "        # spark_app_name=\"YFinanceDataFetcher\"\n",
    "        # spark=create_spark_session(spark_app_name)\n",
    "        \n",
    "        # spark = SparkSession.builder.appName(\"YFinanceDataFetcher\").getOrCreate()        \n",
    "        # Distribute (symbol, start_date) pairs across Spark workers\n",
    "\n",
    "        print(symbol_date_pairs)\n",
    "        record_rdd = spark.sparkContext.parallelize(symbol_date_pairs)\n",
    "        \n",
    "        # # Fetch data in parallel using mapPartitions to avoid broadcasting Spark session\n",
    "        mapped_record_rdd = record_rdd.mapPartitions(lambda partition: [record for pair in partition for record in fetch_yfinance_record(pair)])\n",
    "        return mapped_record_rdd\n",
    "        \n",
    "        # # # Convert RDD to DataFrame on the driver node\n",
    "        # result_df = spark.createDataFrame(mapped_record_rdd)  \n",
    "       \n",
    "        # # Define schema\n",
    "\n",
    "        # data = [\n",
    "        #     (\"Alice\", 33, \"New York\"),\n",
    "        #     (\"Bob\", 30, \"San Francisco\"),\n",
    "        #     (\"Charlie\", 35, \"Los Angeles\")\n",
    "        # ]\n",
    "        # columns = [\"Name\", \"Age\", \"City\"]\n",
    "        # result_df = spark.createDataFrame(data, columns)\n",
    "     \n",
    "        # return result_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error paralleling fetch: {e}\")\n",
    "        # return spark.createDataFrame([])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738cd69-ec1e-4273-a825-268cce1a14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81d18d-f8df-4805-aaf2-f5a5b48d9d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
