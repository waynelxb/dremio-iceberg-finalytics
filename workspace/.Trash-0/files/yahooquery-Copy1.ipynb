{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8045f-9ac6-4e49-a85c-a17d1014ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahooquery import Ticker\n",
    "\n",
    "# Get data for Apple\n",
    "TickerList=[\"AAPL\", \"TSLA\"]\n",
    "ticker = Ticker(TickerList)\n",
    "hist_data = ticker.history(period=\"1mo\")\n",
    "print(hist_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e244f7-c6a9-4494-95e3-09786727a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahooquery import Ticker\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def retrieve_data(ticker):\n",
    "    info = Ticker(ticker).history(period=\"1y\")\n",
    "    # print(f\"{ticker} {info.get('regularMarketPrice')} {info.get('marketCap')}\")\n",
    "\n",
    "ticker_list = ['AAPL', 'ORCL', 'PREM.L', 'UKOG.L', 'KOD.L', 'TOM.L', 'VELA.L', 'MSFT', 'AMZN', 'GOOG']\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(retrieve_data, ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43071df5-88be-471f-8b7f-30003b81c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    " \n",
    "ticker_list = ['IBM', 'MSFT', 'AAPL', 'AMZN']\n",
    " \n",
    "# Here we use yf.download function\n",
    "data = yf.download(\n",
    "     \n",
    "    # passes the ticker\n",
    "    tickers=ticker_list,\n",
    "     \n",
    "    # used for access data[ticker]\n",
    "    group_by='ticker',\n",
    " \n",
    ")\n",
    " \n",
    "# used for making transpose\n",
    "data = data.T \n",
    " \n",
    "for t in ticker_list:\n",
    "   \n",
    "    # printing name\n",
    "    print(t)\n",
    "    print('\\n')\n",
    "     \n",
    "    # used data.loc as it takes only index \n",
    "    # labels and returns dataframe\n",
    "    print(data.loc[t])  \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c835f29-d0cc-4973-aaa7-4ba1c2eeeb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = Ticker('aapl', asynchronous=True)\n",
    "\n",
    "# Default period = ytd, interval = 1d\n",
    "df = tickers.history()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e50df-64fa-48fe-a296-82711c5b11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from yahooquery import Ticker\n",
    "\n",
    "funds = ['aapl', 'amzn']\n",
    "\n",
    "ticker_def = Ticker(funds, asynchronous=True) # Make asynchronous requests\n",
    "\n",
    "all = ticker_def.all_modules #asset_profile print(all)\n",
    "\n",
    "all = pd.DataFrame.from_dict(all)\n",
    "all = all.astype(str)\n",
    "\n",
    "#all = all.iloc[0:1] # to select one or more rows\n",
    "\n",
    "output_table_1 = all.copy()\n",
    "print(output_table_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5e441-6d58-4a5e-beee-9918a24092b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "#I am using a csv file with a list of all the tickers which I use to create a pandas dataframe and form a space seperated string of all of the tickers called all_symbols\n",
    "#I have simplified the pandas dataframe to a list for the purpose of this question\n",
    "\n",
    "ticker_list = [\"A\", \"AL\", \"AAP\", \"AAPL\", \"ZBRA\", \"ZION\", \"ZTS\"]\n",
    "all_symbols  = \" \".join(ticker_list)\n",
    "\n",
    "tickers = yf.Tickers(all_symbols)\n",
    "\n",
    "for ticker in ticker_list:\n",
    "    price = tickers.tickers[ticker].info[\"currentPrice\"]\n",
    "    market_cap = tickers.tickers[ticker].info[\"marketCap\"]\n",
    "    print(ticker, market_cap, price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771dfbc8-4116-4d05-8024-92ef1228c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# pip install yfinance\n",
    "import yfinance as yf\n",
    "import time\n",
    " \n",
    "# Time starts from here\n",
    "start = time.time() \n",
    " \n",
    "ticker_list = ['IBM', 'MSFT', 'AAPL', 'AMZN']\n",
    " \n",
    "# Here we use yf.download function\n",
    "data = yf.download(\n",
    "    tickers=ticker_list,\n",
    "    threads=True,\n",
    "    start=\"2024-12-1\", end=\"2025-2-1\", interval=\"1d\",\n",
    "    group_by='Date',\n",
    " \n",
    ")\n",
    " \n",
    "# used for making transpose\n",
    "data = data.T \n",
    " \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa5f3e-7a0b-4903-88e6-21961a5afc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance\n",
    "import datetime as dt\n",
    "\n",
    "enddate = dt.datetime.strptime(\"2021-01-01\", \"%Y-%m-%d\").date()\n",
    "startdate = enddate - dt.timedelta(days=365*5) # for 5 years\n",
    "\n",
    "data = yfinance.download(tickers=\"AAPL\", start=startdate, end=enddate, interval=\"1d\", group_by =\"Ticker\" )\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad4753-7f45-4b9d-9288-abcc2080c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance\n",
    "data = yfinance.download(tickers=\"AAPL\", start=\"2016-01-03\", end=\"2021-01-01\", interval=\"1d\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e027816-5155-4db5-a271-bcc7bcd09054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\"]  # Example: Apple, Microsoft, Google\n",
    "\n",
    "# Download historical data\n",
    "data = yf.download(\n",
    "    tickers=tickers,\n",
    "    start=\"2016-01-03\",\n",
    "    end=\"2021-01-01\",\n",
    "    interval=\"1d\",\n",
    "    group_by=\"ticker\"\n",
    ")\n",
    "\n",
    "# Reshape the data to have a 'Ticker' column\n",
    "all_data = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    df = data[ticker].copy()  # Get data for the specific ticker\n",
    "    df['Ticker'] = ticker  # Add the Ticker column\n",
    "    df.reset_index(inplace=True)  # Reset index to have Date as a column\n",
    "    all_data.append(df)\n",
    "\n",
    "# Concatenate all tickers into a single DataFrame\n",
    "result = pd.concat(all_data)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa2a3b-fd8f-4c72-960c-4932c5d113f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"multi_ticker_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bffe05-4d6e-4597-bab6-600125378661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahooquery import Ticker\n",
    "import pandas as pd\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\"]  # Example: Apple, Microsoft, Google\n",
    "\n",
    "# Initialize Ticker object\n",
    "data = Ticker(tickers)\n",
    "\n",
    "# Fetch historical data\n",
    "hist_data = data.history(start=\"2016-01-03\", end=\"2021-01-01\", interval=\"1d\")\n",
    "\n",
    "# Reshape the data to include a 'Ticker' column\n",
    "# `yahooquery` returns a multi-index DataFrame by default\n",
    "hist_data.reset_index(inplace=True)  # Reset index to make Ticker and Date columns\n",
    "hist_data.rename(columns={\"symbol\": \"Ticker\"}, inplace=True)  # Rename 'symbol' to 'Ticker'\n",
    "\n",
    "# Display the result\n",
    "print(hist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8342c5-e5f5-4121-bd81-2f1e392005b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"yahooquery\")\n",
    "\n",
    "from yahooquery import Ticker\n",
    "import pandas as pd\n",
    "\n",
    "# Your existing code\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "data = Ticker(tickers)\n",
    "hist_data = data.history(start=\"2016-01-03\", end=\"2021-01-01\", interval=\"1d\")\n",
    "hist_data.reset_index(inplace=True)\n",
    "hist_data.rename(columns={\"symbol\": \"Ticker\"}, inplace=True)\n",
    "print(hist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89679ca-0b21-48c3-932b-442a2ebacbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahooquery import Ticker\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "\n",
    "# Initialize Ticker object\n",
    "data = Ticker(tickers)\n",
    "\n",
    "# Fetch historical data\n",
    "hist_data = data.history(start=\"2016-01-03\", end=\"2021-01-01\", interval=\"1d\")\n",
    "\n",
    "# Reshape the data to include a 'Ticker' column\n",
    "hist_data.reset_index(inplace=True)  # Reset index to make Ticker and Date columns\n",
    "hist_data.rename(columns={\"symbol\": \"Ticker\"}, inplace=True)  # Rename 'symbol' to 'Ticker'\n",
    "\n",
    "# Add a new field for the current datetime\n",
    "hist_data[\"Current Datetime\"] = datetime.now()\n",
    "\n",
    "# Display the result\n",
    "print(hist_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee07a6-0c96-4a46-ba8e-255afd7ca317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahooquery import Ticker\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "\n",
    "# Initialize Ticker object\n",
    "data = Ticker(tickers)\n",
    "\n",
    "# Fetch historical data\n",
    "hist_data = data.history(start=\"2016-01-03\", end=\"2021-01-01\", interval=\"1d\")\n",
    "\n",
    "# Reshape the data to include a 'Ticker' column\n",
    "hist_data.reset_index(inplace=True)  # Reset index to make Ticker and Date columns\n",
    "hist_data.rename(columns={\"symbol\": \"Ticker\"}, inplace=True)  # Rename 'symbol' to 'Ticker'\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\"adjclose\", \"dividends\", \"splits\"]\n",
    "hist_data.drop(columns=columns_to_drop, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Add a new field for the current datetime\n",
    "hist_data[\"Current Datetime\"] = datetime.now()\n",
    "\n",
    "# Display the result\n",
    "print(hist_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1690a7b9-e469-4dc1-abef-b167267a89f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WINV', 'RGA', 'POLA', 'SNEX', 'MKFG', 'VYGR', 'RMR', 'LIVE', 'AMPL', 'CYBN', 'UE', 'ASND', 'OGEN', 'HZO', 'RCS', 'LAD', 'NIM', 'BOOT', 'CRVL', 'STG', 'ASUR', 'IMNM', 'EPIX', 'NGD', 'AQB', 'PFE', 'EYEN', 'IPHA', 'CARG', 'TER', 'SALM', 'SUM', 'AMST', 'VRSN', 'MEC', 'CCRD', 'FSI', 'KNOP', 'DOCS', 'NFG', 'KTOS', 'SBT', 'SCOR', 'SAGE', 'NUE', 'RYAN', 'TRP', 'KLTR', 'PRO', 'CMT', 'GLQ', 'BEAT', 'SLRC', 'HRB', 'JBLU', 'OCFT', 'STNG', 'IOR', 'SRTS', 'BMI', 'DCI', 'REPX', 'GRX', 'DOUG', 'CLPR', 'MWA', 'IVR', 'CHW', 'MULN', 'DLHC', 'EXAS', 'VSAT', 'ENIC', 'FHTX', 'AMH', 'TPZ', 'LNSR', 'SKM', 'AN', 'TPVG', 'RYI', 'TDOC', 'STEM', 'KURA', 'NNDM', 'CNK', 'NAT', 'PCOR', 'AGD', 'LOW', 'PPC', 'FNA', 'EPC', 'OGS', 'ECOR', 'BGY', 'OPEN', 'GLYC', 'STRM', 'AOUT', 'BYND', 'IESC', 'WMPN', 'STKL', 'BLIN', 'AVO', 'GF', 'SSD', 'KIO', 'PAI', 'SJT', 'TELA', 'DD', 'WSR', 'PFGC', 'NVR', 'IMRN', 'PCRX', 'GDS', 'BBD', 'DDL', 'WTMAU', 'SNT', 'ASTC', 'TWIN', 'SONX', 'VITL', 'INGN', 'MAQCU', 'GRMN', 'RVLV', 'FVCB', 'ETJ', 'CTSH', 'MMC', 'BBIG', 'PAYC', 'D', 'ZENV', 'LBRT', 'MIGI', 'SURG', 'PHI', 'HNNA', 'PMCB', 'KULR', 'FARM', 'TRVN', 'RVPH', 'TAK', 'KEP', 'WINT', 'CHI', 'DLNG', 'ARLP', 'EMN', 'INZY', 'USFD', 'BAM', 'PG', 'CLBR', 'ALL', 'PLRX', 'CGEM', 'NZF', 'CALX', 'PULM', 'SPG', 'CMAX', 'KYN', 'HUMA', 'NVNO', 'MBCN', 'BIO', 'LKQ', 'ITCI', 'UMH', 'CFLT', 'BAK', 'HWKN', 'CGNX', 'ELS', 'SEED', 'AFL', 'GLW', 'KSM', 'SBEV', 'FICO', 'BANC', 'GPMT', 'IAC', 'KVHI', 'GDDY', 'NYC', 'NWG', 'BCS', 'FLWS', 'AEF', 'WWR', 'EVRG', 'WFC', 'BTG', 'CXM', 'BSM', 'GTEC', 'GFF', 'TV', 'CII', 'WOW', 'DSGN', 'PFX', 'NTST', 'ITP', 'COFS', 'NODK', 'PPG', 'GDYN', 'ROK', 'MESA', 'GURE', 'MRM', 'BDL', 'BEDU', 'BY', 'FLYW', 'CCK', 'MITT', 'OGI', 'TGAAU', 'PAC', 'ALEX', 'SSYS', 'EOD', 'FSLR', 'TREE', 'DSM', 'VEON', 'EZPW', 'TTWO', 'GAMB', 'OGCP', 'MRBK', 'PEGA', 'VOLT', 'STKS', 'NWS', 'UTI', 'CDNA', 'MXL', 'CNET', 'FEDU', 'DSX', 'MOBQ', 'SENS', 'MTN', 'ENR', 'PDD', 'VLRS', 'ISPC', 'STAB', 'ASMB', 'CRWS', 'CRL', 'VST', 'STWD', 'MSA', 'BE', 'PERI', 'AX', 'CCEP', 'ATHA', 'ASLE', 'CXE', 'THO', 'VNT', 'CELC', 'SPIR', 'MEIP', 'AKTX', 'SIFY', 'CHWY', 'GNLN', 'MCBS', 'MTSI', 'GKOS', 'HMST', 'CHCI', 'NTIP', 'ASRV', 'CADE', 'CRESY', 'MCRB', 'SGBX', 'AGI', 'CARV', 'SHG', 'LH', 'CSSE', 'UNIT', 'FWONA', 'FLO', 'MCR', 'DMB', 'DHY', 'GPRK', 'ARHS', 'CVEO', 'GBLI', 'IDA', 'PAG', 'QIPT', 'URI', 'PI', 'IMCR', 'PGRE', 'FIGS', 'AWP', 'WTBA', 'CIF', 'SQNS', 'HWBK', 'FIX', 'HUBG', 'CRT', 'VRE', 'DOX', 'NSTB', 'NMIH', 'VRNA', 'MUFG', 'HTLF', 'RDIB', 'IPW', 'TROX', 'ESLT', 'FEIM', 'DAWN', 'TEAF', 'HRZN', 'BKTI', 'RYN', 'EGHT', 'RFL', 'MCAA', 'ESEA', 'RICK', 'WHF', 'KKR', 'SMTI', 'CMRX', 'GHY', 'TDG', 'OVID', 'WOOF', 'DRD', 'LEN', 'BRAG', 'WEA', 'BANX', 'REG', 'OMQS', 'INTG', 'ESTC', 'IPG', 'RPAY', 'ASH', 'NMM', 'TAL', 'DRVN', 'PBBK', 'SAR', 'EVFM', 'ITW', 'GFS', 'PL', 'ASAI', 'INSI', 'PATK', 'TTD', 'EXPO', 'WY', 'NEO', 'STRT', 'ANET', 'UGP', 'TAOP', 'EIX', 'ACM', 'AWX', 'ADSK', 'ORGN', 'SNDR', 'CMP', 'CHKP', 'PMF', 'AEO', 'GLDD', 'RLYB', 'LSF', 'HFWA', 'WSFS', 'DSL', 'IIIV', 'AVIR', 'MU', 'ENZ', 'KFY', 'OMC', 'JELD', 'COTY', 'PCTTU', 'APEI', 'CRTD', 'DOGZ', 'RLI', 'EEIQ', 'CYTO', 'BEEM', 'SLM', 'CODI', 'BCLI', 'CASY', 'MTC', 'ANGO', 'LUNG', 'FORM', 'BSTZ', 'VRAR', 'TRT', 'BBDO', 'CB', 'HNST', 'CASS', 'PYN', 'EMKR', 'LYRA', 'TATT', 'CBAN', 'NBST', 'WING', 'NXC', 'KYMR', 'NVAX', 'GLRE', 'FCBC', 'GBCI', 'NHTC', 'PCK', 'LOCL', 'OPRX', 'EVER', 'KOSS', 'BTI', 'MRUS', 'ITOS', 'USAP', 'VTYX', 'KWR', 'CAH', 'OXY', 'PDEX', 'LNTH', 'CDW', 'FGEN', 'NTIC', 'BELFB', 'TKNO', 'ETR', 'RPM', 'TJX', 'ENG', 'EPSN', 'PRLD', 'MRNA', 'RGT', 'BCPC', 'WATT', 'EOG', 'INMB', 'CP', 'MMD', 'JCI', 'PLBC', 'RMTI', 'MOV', 'BITF', 'MCN', 'PCN', 'FOX', 'ALTM', 'JBHT', 'EXPE', 'MVIS', 'GBIO', 'EMF', 'YALA', 'PODD', 'BTZ', 'MCO', 'ONB']\n"
     ]
    }
   ],
   "source": [
    "# databases:\n",
    "#   postgresql:\n",
    "#     finalytics:\n",
    "#       host: \"192.168.1.222\"\n",
    "#       port: \"5432\"\n",
    "#       user: \"postgres\"\n",
    "#       password: \"HDdimension1!\"\n",
    "#       database: \"finalytics\"\n",
    "#       driver: \"org.postgresql.Driver\" \n",
    "\n",
    "\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "# Database connection details\n",
    "host = \"192.168.1.222\"  # e.g., \"localhost\" or database server address\n",
    "dbname = \"finalytics\"\n",
    "user = \"postgres\"\n",
    "password = \"HDdimension1!\"\n",
    "\n",
    "# Connect to PostgreSQL database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        dbname=dbname,\n",
    "        user=user,\n",
    "        password=password\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Query to fetch the specific field (column)\n",
    "    column_name = \"symbol\"  # Replace with your field name\n",
    "    table_name = \"fin.vw_etl_stock_eod_start_date_grouped\"   # Replace with your table name\n",
    "    query = f\"SELECT {column_name} FROM {table_name} WHERE group_number = 1;\"\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Fetch all rows from the executed query\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Extract the values from the column into a list\n",
    "    values_list = [row[0] for row in rows]\n",
    "\n",
    "    # Print the resulting list\n",
    "    print(values_list)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33899a61-94b9-4bc9-9822-bb9b64b647fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date symbol        open        high         low       close  \\\n",
      "0    2025-01-06   WINV   12.060000   12.060000   12.060000   12.060000   \n",
      "1    2025-01-07   WINV   12.060000   12.060000   12.060000   12.060000   \n",
      "2    2025-01-06    RGA  218.490005  221.610001  217.619995  218.669998   \n",
      "3    2025-01-07    RGA  220.029999  223.279999  218.210007  221.740005   \n",
      "4    2025-01-06   POLA    3.180000    3.670000    3.120000    3.270000   \n",
      "..          ...    ...         ...         ...         ...         ...   \n",
      "982  2025-01-07    BTZ   10.550000   10.550000   10.450000   10.490000   \n",
      "983  2025-01-06    MCO  478.720001  479.829987  472.779999  473.140015   \n",
      "984  2025-01-07    MCO  473.140015  473.670013  462.549988  464.000000   \n",
      "985  2025-01-06    ONB   21.510000   21.840000   21.260000   21.260000   \n",
      "986  2025-01-07    ONB   21.350000   21.480000   20.879999   21.040001   \n",
      "\n",
      "      volume                import_time  \n",
      "0          0 2025-01-09 01:23:14.973969  \n",
      "1          0 2025-01-09 01:23:14.973969  \n",
      "2     623900 2025-01-09 01:23:14.973969  \n",
      "3     646400 2025-01-09 01:23:14.973969  \n",
      "4      58800 2025-01-09 01:23:14.973969  \n",
      "..       ...                        ...  \n",
      "982   228900 2025-01-09 01:23:14.973969  \n",
      "983   552600 2025-01-09 01:23:14.973969  \n",
      "984   719700 2025-01-09 01:23:14.973969  \n",
      "985  2665700 2025-01-09 01:23:14.973969  \n",
      "986  3261200 2025-01-09 01:23:14.973969  \n",
      "\n",
      "[987 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from yahooquery import Ticker\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# List of tickers\n",
    "# tickers = [\"FSNB\", \"MSFT\", \"GOOGL\"]\n",
    "tickers=values_list\n",
    "# Initialize Ticker object\n",
    "data = Ticker(tickers)\n",
    "\n",
    "# Fetch historical data\n",
    "hist_data = data.history(start=\"2025-01-06\", end=\"2025-01-08\", interval=\"1d\")\n",
    "\n",
    "# Reshape the data to include a 'Ticker' column\n",
    "hist_data.reset_index(inplace=True)  # Reset index to make Ticker and Date columns\n",
    "\n",
    "# # Select only required columns\n",
    "columns_to_select = [\"date\", \"symbol\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "hist_data = hist_data[columns_to_select]\n",
    "\n",
    "# Add a new field for the current datetime\n",
    "hist_data[\"import_time\"] = datetime.now()\n",
    "\n",
    "# Display the result\n",
    "print(hist_data)\n",
    "\n",
    "\n",
    "# Convert pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(hist_data)\n",
    "\n",
    "# Show the Spark DataFrame\n",
    "spark_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0bdd9644-d892-4c7e-b0ba-25479c6ea284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12 added as a dependency\n",
      "software.amazon.awssdk#bundle added as a dependency\n",
      "software.amazon.awssdk#url-connection-client added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d94a1e01-7260-4900-ba02-d67a27d2fabe;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.7.3 in central\n",
      "\tfound org.checkerframework#checker-qual;3.42.0 in central\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 in central\n",
      "\tfound org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.77.1 in central\n",
      "\tfound software.amazon.awssdk#bundle;2.24.8 in central\n",
      "\tfound software.amazon.awssdk#url-connection-client;2.24.8 in central\n",
      "\tfound software.amazon.awssdk#utils;2.24.8 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in central\n",
      "\tfound software.amazon.awssdk#annotations;2.24.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound software.amazon.awssdk#http-client-spi;2.24.8 in central\n",
      "\tfound software.amazon.awssdk#metrics-spi;2.24.8 in central\n",
      ":: resolution report :: resolve 505ms :: artifacts dl 38ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.42.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.7.3 from central in [default]\n",
      "\torg.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.77.1 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\tsoftware.amazon.awssdk#annotations;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#http-client-spi;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#metrics-spi;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#url-connection-client;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#utils;2.24.8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   0   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d94a1e01-7260-4900-ba02-d67a27d2fabe\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/20ms)\n",
      "25/01/09 01:27:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------------------+------------------+------------------+------------------+------+--------------------+\n",
      "|      date|symbol|              open|              high|               low|             close|volume|         import_time|\n",
      "+----------+------+------------------+------------------+------------------+------------------+------+--------------------+\n",
      "|2025-01-06|  WINV|  12.0600004196167|  12.0600004196167|  12.0600004196167|  12.0600004196167|     0|2025-01-09 01:23:...|\n",
      "|2025-01-07|  WINV|  12.0600004196167|  12.0600004196167|  12.0600004196167|  12.0600004196167|     0|2025-01-09 01:23:...|\n",
      "|2025-01-06|   RGA|218.49000549316406|221.61000061035156| 217.6199951171875| 218.6699981689453|623900|2025-01-09 01:23:...|\n",
      "|2025-01-07|   RGA|220.02999877929688|223.27999877929688| 218.2100067138672|221.74000549316406|646400|2025-01-09 01:23:...|\n",
      "|2025-01-06|  POLA| 3.180000066757202|3.6700000762939453| 3.119999885559082|3.2699999809265137| 58800|2025-01-09 01:23:...|\n",
      "|2025-01-07|  POLA|3.2799999713897705|3.5899999141693115| 3.200000047683716| 3.319999933242798|114400|2025-01-09 01:23:...|\n",
      "|2025-01-06|  SNEX|102.43000030517578|104.73999786376953| 102.1500015258789| 103.2699966430664|213000|2025-01-09 01:23:...|\n",
      "|2025-01-07|  SNEX|103.30999755859375|103.30999755859375|  99.6500015258789|100.05999755859375|235200|2025-01-09 01:23:...|\n",
      "|2025-01-06|  MKFG|               3.5|3.5869998931884766|3.4600000381469727| 3.490000009536743| 63900|2025-01-09 01:23:...|\n",
      "|2025-01-07|  MKFG|               3.5|3.5450000762939453|3.4100000858306885|3.4100000858306885| 48600|2025-01-09 01:23:...|\n",
      "|2025-01-06|  VYGR| 6.099999904632568| 6.150000095367432|  5.96999979019165| 6.019999980926514|481800|2025-01-09 01:23:...|\n",
      "|2025-01-07|  VYGR| 6.010000228881836| 6.269999980926514| 5.889999866485596| 5.920000076293945|248700|2025-01-09 01:23:...|\n",
      "|2025-01-06|   RMR|  20.3700008392334|20.440000534057617|19.899999618530273| 19.90999984741211|153800|2025-01-09 01:23:...|\n",
      "|2025-01-07|   RMR|19.899999618530273|20.059999465942383|  19.3799991607666|19.389999389648438|162700|2025-01-09 01:23:...|\n",
      "|2025-01-06|  LIVE| 9.229999542236328| 9.229999542236328| 8.760000228881836| 9.140000343322754|  3100|2025-01-09 01:23:...|\n",
      "|2025-01-07|  LIVE|               9.0| 9.390000343322754|              8.75| 9.180000305175781| 11300|2025-01-09 01:23:...|\n",
      "|2025-01-06|  AMPL|11.760000228881836|11.829999923706055|11.470000267028809|11.510000228881836|405100|2025-01-09 01:23:...|\n",
      "|2025-01-07|  AMPL|11.510000228881836|11.630000114440918|10.479999542236328|10.600000381469727|398800|2025-01-09 01:23:...|\n",
      "|2025-01-06|  CYBN|10.279999732971191|10.649999618530273|            10.125|10.649999618530273|206200|2025-01-09 01:23:...|\n",
      "|2025-01-07|  CYBN|10.699999809265137|10.729999542236328| 9.859999656677246|10.029999732971191|252200|2025-01-09 01:23:...|\n",
      "+----------+------+------------------+------------------+------------------+------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import nbimporter\n",
    "from datetime import datetime, date\n",
    "import yfinance as yf\n",
    "import time\n",
    "import random\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType,  DateType, TimestampType\n",
    "from pyspark.sql.functions import to_date, to_timestamp\n",
    "from lab_database_manager import PgDBManager\n",
    "from lab_spark import create_spark_session\n",
    "from lab_schema_manager import SchemaManager\n",
    "\n",
    "# Create Spark Session\n",
    "connection_config_file=\"cfg_connections.yaml\"\n",
    "spark_app_name=\"raw_yfinance\"\n",
    "spark=create_spark_session(connection_config_file, spark_app_name)\n",
    "# spark.sql(\"CREATE NAMESPACE IF NOT EXISTS nessie.raw;\")\n",
    "\n",
    "\n",
    "# Convert pandas DataFrame to Spark DataFrame\n",
    "spark_df = spark.createDataFrame(hist_data)\n",
    "\n",
    "# Show the Spark DataFrame\n",
    "spark_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eb3aca44-9d58-4686-8bc3-3f873dc70397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- import_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0e9457c-7eaf-4b52-be1f-115f9dcad106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Tickers: ['INKT' 'INNV' 'INTE' 'INTEU' 'INVZ' 'IOBT' 'IONM' 'IONQ' 'IPSC' 'IREN'\n",
      " 'IRRX' 'INSI' 'IVT' 'IXAQ' 'IXAQU' 'JANX' 'JCE' 'JFR' 'JGH' 'JLS' 'JMM'\n",
      " 'JOBY' 'JPC' 'JPI' 'JQC' 'JRI' 'JRS' 'JSPR' 'JWEL' 'JXN' 'JZXN' 'KACLU'\n",
      " 'KARO' 'KAVL' 'KD' 'KIND' 'KIO' 'FBRX' 'KORE' 'KPLT' 'KPRX' 'KYMR' 'KRT'\n",
      " 'FHTX' 'SWBI' 'TMQ' 'DOLE' 'RLYB' 'SGML']\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "distinct_tickers = hist_data[\"symbol\"].unique()\n",
    "\n",
    "# Display the result\n",
    "print(\"Distinct Tickers:\", distinct_tickers)\n",
    "distinct_ticker_count = hist_data[\"symbol\"].nunique()\n",
    "\n",
    "print(distinct_ticker_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22168854-440f-47aa-9be7-f0c13adef044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
